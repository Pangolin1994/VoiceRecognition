{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import librosa\n",
    "from librosa import effects\n",
    "import wave\n",
    "import pyaudio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Input, Conv2D,\n",
    "    Flatten, LSTM, concatenate, TimeDistributed)\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "main = 'D:/Загрузки/train-clean/train/'\n",
    "\n",
    "os.environ['TF_CUDNN_DETERMINISM'] = '1'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "# For preventing failing during training on gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "speak_with_dirs = [(e[0], e[2]) for e in os.walk(main)]\n",
    "\n",
    "# Remove non-parents dirs\n",
    "speak_with_dirs = [e for e in speak_with_dirs\n",
    "                   if len(e[1]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get closest path = it's path to parent dir\n",
    "parents = list(map(lambda e: e[0], speak_with_dirs))\n",
    "\n",
    "# Last dir in parent path = speaker's target\n",
    "targets = list(map(lambda s: s.split('\\\\')[-1], parents))\n",
    "\n",
    "# Paths without targets\n",
    "paths = list(map(lambda s: '/'.join(s.split('\\\\')[:-1]), parents))\n",
    "\n",
    "# Associate with speaker files\n",
    "wavs = list(map(lambda e: e[1], speak_with_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering by flac extension\n",
    "wavs = [list(filter(lambda s: s.endswith('.flac'), e))\n",
    "        for e in wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect files with relevant target and filepaths\n",
    "wavs = [[(path, file, target) for file in files]\n",
    "        for target, files, path in zip(targets, wavs, paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "wavs = list(itertools.chain(*wavs))\n",
    "print(f'Count of audio files {len(wavs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all = pd.DataFrame(wavs, columns=[\n",
    "    'Parent', 'File', 'Target'\n",
    "])\n",
    "\n",
    "fulls = list(map(\n",
    "    lambda e: '/'.join(e),\n",
    "    zip(df_all['Parent'], df_all['Target'], df_all['File'])\n",
    "))\n",
    "df_all['Full_path'] = fulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vc = df_all['Target'].value_counts()\n",
    "\n",
    "# Select n most popular speakers by id\n",
    "count_speakers = 5\n",
    "top_speaks = target_vc[:count_speakers]\n",
    "top_ids = top_speaks.index\n",
    "\n",
    "df = df_all[df_all['Target'].isin(top_ids)]\n",
    "print(f'{df.shape[0]} records by {len(top_ids)} speakers')\n",
    "\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset of threes building.\n",
    "Each samples includes anchor, positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#three_lens = top_speaks // 2\n",
    "\n",
    "# a - Anchors and positives collection\n",
    "a = []\n",
    "for label in top_ids:\n",
    "    b = df[df['Target'] == label]\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df1 = pd.concat(a)\n",
    "# Records count for each speaker\n",
    "three_len = 30\n",
    "\n",
    "# Collections of anchors and positives examples paths\n",
    "anchors = []\n",
    "positives = []\n",
    "\n",
    "for label in top_ids:\n",
    "    sub_df = df1.loc[df1['Target'] == label,\n",
    "                     ['Full_path', 'Target']]\n",
    "    \n",
    "    anchor = sub_df.iloc[:three_len]\n",
    "    positive = sub_df.iloc[three_len: 2*three_len]\n",
    "    \n",
    "    anchors.append(anchor['Full_path'].to_numpy())\n",
    "    positives.append(positive['Full_path'].to_numpy())\n",
    "    \n",
    "print('Selected {} files'.format(three_len * count_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "anchors = np.array(list(itertools.chain(*anchors)))\n",
    "positives = np.array(list(itertools.chain(*positives)))\n",
    "\n",
    "# Dataset length\n",
    "samples_count = len(anchors)\n",
    "\n",
    "# Select random samples of rest dataset\n",
    "# to build impostor set \n",
    "neg_df = df_all[~df_all.index.isin(df.index)]\n",
    "imposts = neg_df.sample(samples_count, random_state=5)\n",
    "negatives = imposts['Full_path'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = anchors.reshape((samples_count, 1))\n",
    "positives = positives.reshape((samples_count, 1))\n",
    "negatives = negatives.reshape((samples_count, 1))\n",
    "\n",
    "dataset = np.concatenate([\n",
    "    anchors, positives, negatives\n",
    "], axis=1)\n",
    "anch_paths, pos_paths, neg_paths = dataset.T\n",
    "\n",
    "# Flat paths of whole dataset\n",
    "ds_all = dataset.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dataset default samples rate\n",
    "samples_rate = 16 * 10**3\n",
    "emph_alpha = 0.95\n",
    "\n",
    "audios = [librosa.load(path, sr=samples_rate)[0]\n",
    "          for path in ds_all]\n",
    "audios = [effects.preemphasis(wave, coef=emph_alpha)\n",
    "          for wave in audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framing and spectrogram parameters\n",
    "frame_sec_size = 0.025\n",
    "overlap_sec_size = 0.02\n",
    "nfft = int(samples_rate * frame_sec_size)\n",
    "win_len = nfft\n",
    "hop_len = int(samples_rate * overlap_sec_size)\n",
    "num_segments = 2\n",
    "num_features = nfft // 2 + 1\n",
    "hamming = sp.signal.windows.hamming(win_len)\n",
    "\n",
    "print('Window {}, overlap: {}\\n'\n",
    "      'consecutive segments: {}\\n'\n",
    "      'frequencies features: {}'.format(\n",
    "          win_len, hop_len,\n",
    "          num_segments, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Clear from silent frames\n",
    "no_silence = [effects.split(wave, frame_length=win_len,\n",
    "                            hop_length=hop_len, top_db=20)\n",
    "              for wave in audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "soundeds = [[wave[d[0]:d[1]] for d in interval]\n",
    "            for wave, interval in zip(audios, no_silence)]\n",
    "\n",
    "soundeds = [np.concatenate(s) for s in soundeds]\n",
    "cleared_lens = [len(s) for s in soundeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Padding or trancating audios to threshold length\n",
    "length_threshold = int(np.quantile(cleared_lens, 0.9))\n",
    "pad_sounds = np.zeros((len(soundeds), length_threshold))\n",
    "\n",
    "for i, s in enumerate(soundeds):\n",
    "    if len(s) > length_threshold:\n",
    "        pad_sounds[i] = s[:length_threshold]\n",
    "    else:\n",
    "        pad_sounds[i, :len(s)] = s\n",
    "\n",
    "d = pad_sounds.reshape((samples_count, 3, -1))\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dur = length_threshold / samples_rate\n",
    "print(f'Audio duration: {audio_dur}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Spectrogram segmentation over time\n",
    "   Below - function dividing spectrogram array into segments\n",
    "   of num_segs consecutive pieces of full spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def segment_spectrogram(stft_data, num_segs, num_ftrs):\n",
    "    concats = np.concatenate([stft_data[:, 0:num_segs-1], stft_data], axis=1)\n",
    "    stft_segs = np.zeros((num_ftrs, num_segs,\n",
    "                          concats.shape[1] - num_segs + 1))\n",
    "\n",
    "    for index in range(concats.shape[1] - num_segs + 1):\n",
    "        stft_segs[:, :, index] = concats[:, index:index + num_segs]\n",
    "        \n",
    "    shape = stft_segs.shape\n",
    "    stft_segs = np.reshape(stft_segs, (\n",
    "        shape[0], shape[1], 1, shape[2]\n",
    "    ))\n",
    "    stft_segs = np.transpose(\n",
    "        stft_segs, (3, 0, 1, 2)\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    return stft_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(wave, _nfft, _hop_len, _win_len, _window):\n",
    "    spec = librosa.stft(wave, n_fft=_nfft, hop_length=_hop_len,\n",
    "                        win_length=_win_len, window=_window)\n",
    "    spec = np.abs(spec)\n",
    "    spec_mean = np.mean(spec)\n",
    "    spec_std = np.std(spec)\n",
    "    spec = (spec - spec_mean) / spec_std\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "spec_shape = (len(d), length_threshold // hop_len + 1,\n",
    "              num_features, num_segments, 1)\n",
    "anch_specs = np.empty(spec_shape, np.float32)\n",
    "pos_specs = np.empty(spec_shape, np.float32)\n",
    "neg_specs = np.empty(spec_shape, np.float32)\n",
    "\n",
    "for i, three in enumerate(d):\n",
    "    anch_wave, pos_wave, neg_wave = three\n",
    "    \n",
    "    anch_spec = get_spectrogram(anch_wave, nfft, hop_len,\n",
    "                                win_len, hamming)\n",
    "    pos_spec = get_spectrogram(pos_wave, nfft, hop_len,\n",
    "                               win_len, hamming)\n",
    "    neg_spec = get_spectrogram(neg_wave, nfft, hop_len,\n",
    "                               win_len, hamming)\n",
    "    \n",
    "    anch_features = segment_spectrogram(\n",
    "        anch_spec, num_segments, num_features)\n",
    "    anch_specs[i] = anch_features\n",
    "    \n",
    "    pos_features = segment_spectrogram(\n",
    "        pos_spec, num_segments, num_features)\n",
    "    pos_specs[i] = pos_features\n",
    "    \n",
    "    neg_features = segment_spectrogram(\n",
    "        neg_spec, num_segments, num_features)\n",
    "    neg_specs[i] = neg_features\n",
    "    \n",
    "print('Spectrogram shape {}'.format(spec_shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Spectrogram convolution class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramConvolution:\n",
    "    def __init__(self, _shape):\n",
    "        self.conv1 = Conv2D(filters=1, input_shape=_shape[1:],\n",
    "                            kernel_size=(5, 3), strides=1,\n",
    "                            activation=relu, padding='same')\n",
    "        self.conv2 = Conv2D(filters=1, kernel_size=(5, 3),\n",
    "                            strides=1, activation=relu, padding='same')\n",
    "        \n",
    "        self.distr = TimeDistributed(self.conv1)\n",
    "        self.distr2 = TimeDistributed(self.conv2)\n",
    "        self.flat = Flatten()\n",
    "\n",
    "    def convolute(self, inputs):\n",
    "        inputs = self.distr(inputs)\n",
    "        inputs = self.distr2(inputs)\n",
    "        return self.flat(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_shape = anch_specs.shape[1:]\n",
    "print(f'Input to convolution: {_input_shape}')\n",
    "spec_conv = SpectrogramConvolution(_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conv_anchors = spec_conv.convolute(anch_specs)\n",
    "conv_pos = spec_conv.convolute(pos_specs)\n",
    "conv_neg = spec_conv.convolute(neg_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "timed_shape = (conv_anchors.shape[0],\n",
    "               _input_shape[0], -1)\n",
    "\n",
    "conv_anchors = tf.reshape(conv_anchors, timed_shape).numpy()\n",
    "conv_pos = tf.reshape(conv_pos, timed_shape).numpy()\n",
    "conv_neg = tf.reshape(conv_neg, timed_shape).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(Loss):\n",
    "    def __init__(self, margin):\n",
    "        self.margin = margin\n",
    "        super(TripletLoss, self).__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        assert y_pred.shape[0] == 3\n",
    "        anchor, positive, negative = tf.unstack(y_pred)\n",
    "        pos_dist = K.sum(K.square(anchor - positive), axis=-1)\n",
    "        neg_dist = K.sum(K.square(anchor - negative), axis=-1)\n",
    "        base_loss = pos_dist - neg_dist + self.margin\n",
    "        return K.mean(K.maximum(base_loss, 0.0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_rnn(_shape, out_units):\n",
    "    inp = Input(shape=_shape, name='input')\n",
    "    lstm1 = LSTM(16, return_sequences=True,\n",
    "                 name='seq2seq')(inp)\n",
    "    lstm2 = LSTM(out_units, name='seq2one')(lstm1)\n",
    "    out = Flatten(name='flattened')(lstm2)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_siam(input_shape, out_units,\n",
    "               optimizer, loss):\n",
    "    anchor_input = Input(shape=input_shape, name='anchor')\n",
    "    positive_input = Input(shape=input_shape, name='positive')\n",
    "    negative_input = Input(shape=input_shape, name='negative')\n",
    "\n",
    "    rnn = base_rnn(input_shape, out_units)\n",
    "    anch_out = rnn(anchor_input)\n",
    "    pos_out = rnn(positive_input)\n",
    "    neg_out = rnn(negative_input)\n",
    "    \n",
    "    out1 = tf.expand_dims(anch_out, axis=0)\n",
    "    out2 = tf.expand_dims(pos_out, axis=0)\n",
    "    out3 = tf.expand_dims(neg_out, axis=0)\n",
    "    output = concatenate([out1, out2, out3], axis=0)\n",
    "\n",
    "    model = Model(inputs=[\n",
    "        anchor_input, positive_input, negative_input\n",
    "    ], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_out_units = 128\n",
    "siam_input = conv_anchors.shape[1:]\n",
    "optim = SGD()\n",
    "_margin = 0.15\n",
    "triplet = TripletLoss(margin=_margin)\n",
    "\n",
    "siam = build_siam(input_shape=siam_input,\n",
    "    out_units=_out_units, optimizer=optim,\n",
    "    loss=triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_len = 0\n",
    "train_data = [conv_anchors[test_len:],\n",
    "              conv_pos[test_len:],\n",
    "              conv_neg[test_len:]]\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Dummy 'true' labels to provide gradients\n",
    "dummy_labels = np.zeros((len(train_data[0]),))\n",
    "\n",
    "history = siam.fit(train_data, y=dummy_labels,\n",
    "    epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "epochs = np.arange(1, len(loss)+1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(epochs, loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Triplet loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database encodings creation.\n",
    "One vector per recognized speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extract convolution vectors for each anchor\n",
    "# Unique labels\n",
    "user_labels = top_ids.to_numpy()\n",
    "# Unique encodings (one-to-one)\n",
    "target_convs = np.asarray([\n",
    "    conv_anchors[i] for i in range(0, len(conv_anchors), three_len)\n",
    "])\n",
    "target_convs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Empty dummy variable to substitute pos and neg inputs\n",
    "## Only anchor prediction will be used further\n",
    "dummy_x = np.empty(target_convs.shape)\n",
    "verify_data =  [target_convs, dummy_x, dummy_x]\n",
    "\n",
    "## Predict vectors for convolution in database\n",
    "## Using direct model call instead of predict due to vary small amount of data\n",
    "verify_vects = siam(verify_data)[0]\n",
    "\n",
    "print('There are {}-length encoding for each of {} speakers'.format(\n",
    "    verify_vects.shape[1], verify_vects.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {label: verify_vects[i]\n",
    "            for i, label in enumerate(user_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify one record with known database\n",
    "def identity_verification(audio_conv, db: dict, model):\n",
    "    assert len(audio_conv.shape) == 2\n",
    "    min_dist = 1\n",
    "    verified = False\n",
    "    identity = None\n",
    "    \n",
    "    audio_conv = tf.expand_dims(audio_conv, axis=0)\n",
    "    dummy_vect = np.empty(audio_conv.shape)\n",
    "    datas = [audio_conv, dummy_vect, dummy_vect]\n",
    "    \n",
    "    encoding = model(datas)\n",
    "    \n",
    "    for label, db_enc in db.items():\n",
    "        dist = la.norm(db_enc - encoding)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = label\n",
    "            verified = True\n",
    "            \n",
    "    return min_dist, verified, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, is_verif, label = identity_verification(\n",
    "    conv_anchors[0], database, siam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_loss = siam.evaluate(train_data, dummy_labels)\n",
    "eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_data = [conv_anchors[:test_len],\n",
    "             conv_pos[:test_len],\n",
    "             conv_neg[:test_len]]\n",
    "\n",
    "# Batch size = test dataset length ?!\n",
    "preds = siam.predict(test_data, batch_size=test_len)\n",
    "test_loss = triplet(None, preds)\n",
    "print(f'Test triplet loss: {test_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}